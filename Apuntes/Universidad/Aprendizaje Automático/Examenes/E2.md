# EJ 1
<<<<<<< Updated upstream
<<<<<<< Updated upstream
<<<<<<< Updated upstream
=======

>>>>>>> Stashed changes
Considere la clase de los clasificadores basados en Máquinas de Soporte de Vectores (Hard and Soft) y la clase de los clasificadores basados en modelos de redes neuronales feed-forward t de 3 capas totalmente conectadas con funciones activación sigmoidal. Considere el caso de un problema de clasificación con etiquetas ruidosas. Diga y justifique con argumentos:
=======
Considere la clase de los clasificadores basados en Máquinas de Soporte de Vectores (Hard and Soft) y la clase de los clasificadores basados en modelos de redes neuronales feed-forward t de 3 capas otalmnerte conectadas con funciones activación sigmoidal. Considere el caso de un problema de clasificación con etiquetas ruidosas. Diga y justifique con argumentos:
>>>>>>> Stashed changes
=======
Considere la clase de los clasificadores basados en Máquinas de Soporte de Vectores (Hard and Soft) y la clase de los clasificadores basados en modelos de redes neuronales feed-forward t de 3 capas otalmnerte conectadas con funciones activación sigmoidal. Considere el caso de un problema de clasificación con etiquetas ruidosas. Diga y justifique con argumentos:
>>>>>>> Stashed changes

a) ¿Que garantías de aprendizaje subyacen a cada clase?

b) ¿Cuál es la relevancia del tamaño muestral en cada caso?

c) Analice la capacidad de ajuste y de generalización en cada clase.

  

Conteste con argumentos técnicos
### Solución
<<<<<<< Updated upstream
<<<<<<< Updated upstream
a) Independientemente de la d_vc del modelo concreto, las RRNN y clasificadores SVM son  ejemplos típicos de  aplicación de la regla  de aprendizaje SRM. En el caso de RRNN con d_vc finita serían un ejemplo de regla ERM con minimización del error E_in,.
=======
a) Independientemente de la d_vc del modelo concreto, las RR.NN. y clasificadores SVM son  ejemplos típicos de  aplicación de la regla  de aprendizaje SRM. En el caso de RRNN con d_vc finita serían un ejemplo de regla ERM con minimizacíon del error E_in,.
>>>>>>> Stashed changes
=======
a) Independientemente de la d_vc del modelo concreto, las RR.NN. y clasificadores SVM son  ejemplos típicos de  aplicación de la regla  de aprendizaje SRM. En el caso de RRNN con d_vc finita serían un ejemplo de regla ERM con minimizacíon del error E_in,.
>>>>>>> Stashed changes <!--SR:!2000-01-01,1,250!2024-01-06,4,270-->

b) En el caso de clasificadores RRNN el alto número de parámetros a estimar siempre requiere de tamaño muestrales grandes para obtener estimadores estables de todos sus parámetros. En cambio en el caso de los clasificadores basados en SVM  la muestra puede ser pequeña en el caso separable,  si nos permite la estimación de los vectores soporte. En el caso no-separable, este tamaño también dependerá del error de ajuste que fijemos ( usando la cte C de las variables de holgura) pero en el tamaño muestral no es un elemento tan esencial en estos clasificadores como lo es en los modelos de las RRNN.

c) Esta clase de funciones RRNN-FF son conocidos aproximadores universales por tanto su capacidad de aproximación es total. En cambiono no hay garantias de su capacidad de generalización que solo se fija a través de un proceso de validación siendo por tanto muy sensibles a procesos de sobreajuste. En cambio, los clasificadores SVM (hard) aplican el truco del núcleo (funciones Kernel) para expandir la dimenionalidad del espacio y lograr soluciones óptimas de separabilidad. En el caso de etiquetas ruidosas la solución de total separabilidad puede conducir a situaciones de sobreajuste si el núcleo es suficientemente potente ( RBF). Si relajamos la condición de total separabilidad (Soft-SVM)  podemos encontrar una solución óptima con un error de ajuste prefijado. El compromiso entre capacidad de generalización y error de ajuste puede también  expresarse como un problema de regularización de la función perdida "Hinge" definida a partir de las rectricciones.

# EJ 2
 Considere un problema de clasificación que queremos resolverlo en un espacio de dimensión mayor al espacio muestral. Para ello usamos dos transformaciones no lineales de dimensión finita  $\Phi_1$ y $\Phi_2$  y sus correspondientes funciones de núcleo $K_1$ y $K_2$. Ahora definimos dos  nuevas transformaciones como $\Phi_3({\bf x})=(\Phi_1({\bf x}),\Phi_2({\bf x}))$ y $\Phi_4= \Phi_1({\bf x}) \cdot \Phi_2({\bf x})^T$. 

a) Expresar los kernels correspondiente a $\Phi_3$  y $\Phi_4$ en términos de $K_1$ y $K_2$.  

b) ¿Que conclusiones saca respecto de $K_1+K_2$ y $K_1\cdot K_2$?

> $\Phi_{3}(x)=(\Phi_{1}(x),\Phi_{2}(x))$


### Solución
1.- $\Phi_3({\bf x})=(\Phi_1({\bf x}),\Phi_2({\bf x}))$  por tanto $K_3({\bf x},{\bf x^{'}})=(\Phi_3({\bf x})^T \Phi_3({\bf x'})=(\Phi_1({\bf x}), \Phi_2({\bf x}))^T {\Phi_1({\bf x^{'}}) \brack \Phi_2({\bf x^{'}}))} = K_1({\bf x},{\bf x^{'}})+  K_2({\bf x},{\bf x^{'}})$ 

  

2.- $\Phi_4({\bf x})=\Phi_1({\bf x})\Phi_2({\bf x})^T$  por tanto $$K_4({\bf x},{\bf x^{'}})=(\Phi_4({\bf x}))^T \Phi_4({\bf x'})= (\Phi_1({\bf x})\Phi_2({\bf x})^T)^T \Phi_1({\bf x^{'}})\Phi_2({\bf x^{'}})^T = \Phi_2({\bf x})\Phi_1({\bf x})^T\Phi_1({\bf x^{'}})\Phi_2({\bf x^{'}})^T = \Phi_2({\bf x}) K_1({\bf x},{\bf x^{'}}) \Phi_2({\bf x^{'}})^T= K_1({\bf x},{\bf x^{'}}) K_2({\bf x},{\bf x^{'}})$$  
3.- Dado que las matrices de Gram (covarianza) calculadas a partir de "kernels" son semidefinida positiva y simétricas, la suma y el producto permanecen semidefinidas positivas y simétricas. Por tanto si $K_1$ y $K_2$ son "kernels" tambien lo son $K_3$ y $K_4$.

# EJ 3
Suponga un problema de predicción $({\cal f},{\cal H},{\cal A},{\cal P} )$ bien definido. Suponga que la clase de funciones ${\cal H}$ es suficientemente compleja como  para hacer que $E_{in} \rightarrow 0$ para cualquier muestra de un tamaño dado N.  
  
a) Analice todas las posibles fuentes de error presentes en en el proceso de ajuste de una hipótesis y diga:  
  
a)  ¿En esta situación hay presencia de sobreajuste ?  
b  ¿Cómo sería la evolución del sobreajuste cuando se va reduciendo  la complejidad de la clase  ${\cal H}$?  
c) ¿En que afectaría a su análisis  que el tamaño  N  de la muestra crezca o decrezca ?  
  
Justifique todas sus afirmaciones

### Solución
Los datos siempre están contaminados por algún error ( pero no sabemos cual). Por tanto si la clase de funciones es capaz de hacer $E_{in}=0$ para toda muestra de tamaño N , dicha clase de funciones podemos admitir que sufre de severo sobrejauste al ajustar el error estocástico. Analicemos los casos

a) El análisis que aquí se efectúa supone que la función que genera los datos no esta contenida en la clase de funciones usada.

Si comenzamos a reducir la complejidad de la clase ${\cal H}$ se producirá una disminución del ajuste del error estocástico. Sabemos que la varianza de la clase de funciones disminuirá conforme vayamos reduciendo la clase de funciones y con la hipotesis establecida el sesgo irá aumentando.  En este compromiso entre errores gana en intensidad la disminución por perdida de varianza de la clase de funciones, lo que hará que el sobreajuste global disminuya. Este decrecimiento de sobreajuste se mantiene hasta que la capacidad de la clase de funciones  para ajustar la variabilidad de los datos de la muestra sea claramente insuficiente en cuyo caso el error determinístico (sesgo) comenzará a crecer más que la disminución del error por menor variabilidad de la clase de funciones y el sobreajuste comenzará a crecer de nuevo.

b) Cuando el tamaño de la muestra N crece o decrece el análisis anterior no cambia en nada, ya que no depende de N. Solo depende de N la complejidad de la clase de funciones que alcanza el error mínimo de ajuste. Lo único que podemos decir es que, en general,  la complejidad de la clase que alcanza el ajuste óptimo será creciente con N.

# EJ 4
Considere la siguiente modificación del algoritmo Perceptron: En cada iteración k:   

a) calcula la distancia de cada punto muestral x  al hiperplano definido por  w_k

b) Adapta el hiperplano con la regla: $w_{k+1}= w_{k}+ y^{*}x^{*}$  donde $x^*$ es el punto peor clasificado, es decir, con mayor distancia al hiperplano e $y^*$ su etiqueta.

c) El algoritmo itera indefinidamente hasta que en dos iteraciones consecutivas el valor de $w_k$ no cambie.

Analize la situación y diga  

a) ¿Converge el nuevo algoritmo a alguna solución? Justifique su contestación

b) En caso afirmativo de convergencia, ¿que clase de  solución obtiene? Justifique los argumentos.


Conteste con argumentos técnicos
### Solución
a) Converge seguro a una solución separable porque el nuevo algoritmo, respecto del perceptron, solo cambia el orden de reexploración de los datos y eso no afecta a la convergencia del perceptron. Una vez el hiperplano es separador el algoritmo va maximizando la distancia de los puntos al hiperplano y por tanto maximizando la distancia  entre los puntos relevantes que lo definen. 

b) La solución es la misma de un SVM ya que maximiza el margen

# EJ 5
Considere un problema de clasificación binario con muestras en un espacio 3D. Dispone de 1000 muestras pero además comentar que ese tipo de  problemas  puede ser separables. Para corroborarlo ajusta un perceptron y obtiene  $E_{in} = 0$. Entonces alguien le comenta que posiblemente haya cometido data snooping. Analice la situación y diga si la información recibida condiciona de alguna manera el cálculo de la cota de error que se obtiene a partir del perceptron ajustado.

Justifique con argumentos técnicos
### Solución
La información que nos dan es de separabilidad,  que es una información genérica ya que cualquier clasificador con d_VC= infinito separa cualquier muestra. Lo que aplicamos y obtenemos es separabilidad lineal por tanto dimension VC finita. Los resukltados obtenidos son legitimos y correctos.

# EJ 6
Identifique las ventajas e inconvenientes del algoritmo SVM-soft, respecto de otros clasificadores binarios que hemos estudiado: perceptron y regresión logística . Analice el  caso separable y no separable.   

  

Conteste con argumentos técnicos
### Solución
La estrecha relación entre el algoritmo SVM-soft y los algoritmos Perceptron(P) , RL se establece con la formulación de todos ellos como un problema de regularización con un mismo regularizador y distinta función de perdida. En ese contexto, el análisis comparativo se centra en las propiedades de la función de perdida usada por cada uno de ellos.

Caso separable: En este caso SVM-soft alcanza la solución óptima en términos de menor dimensión de VC, ya que su función de perdida busca el hiperplano solución con máximo margen de separación Las funciones de perdida del Perceptron solo busca una solución separable. Por otro lado RL optimiza una perdida extraida de la optimización de la  verosimilitud de la muestra que no implica la solución de mayor separabilidad para todas las distribuciones de cada clase aunque en algunos casos podría alcanzarla.

Caso no separable:  O no existe solución óptima en términos de separabilidad o no está definida de forma unica.  Los tres casos se pueden formular como un problema de regularización a través de una constante de ponderación sobre los pesos, pero en el caso de SVM-soft  la función de perdida esta asociada a la obtención del máximo margen poara cada valior de la cte prefijado lo que es una garantía de mayor capacidad de generalización. Aunque los demás algoritmos no maximizan el margen frente al error., se ha mostrado experimentalmente que la maximización probabilistica  de  RL permite obtener  soluciones mejor regularizadas que con SVM-soft en casos con alto nivel de ruido.

# EJ 7
Analice los clasificadores basados en  árboles y diga:

a) ¿Son clasificadores PAC? . En caso negativo, ¿que garantías teóricas avalan el funcionamiento de dichos clasificadores?.

b) ¿Existe un algoritmo óptimo para crear un clasificador en árbol binario? Justifique su afirmación

c) Analice como se mide el sesgo y la varianza en una función definida por un árbol y como se puede encontrar un balance entre dichos errores.

Justifique todos sus razonamientos
### Solución
a) El árbol como clasificador tiene dimensión-VC infinita luego no son clasificadores PAC.  El criterio MDL permite establecer el error de generalización del árbol a partir del número de nodos, el tamaño muestral y la dimensión del espacio de características. 

b) No existe. El problema de optimización asociado a la partición de cada nodo, selección de variable y valor óptimo de la misma es un problema NP.  Por ello, os valores de partición de las variables se fijan de antemano y solo se analizan las variables sobre dichos valores. 

b)   Cada árbol desarrollado hasta que cada nodo hoja contenga un solo elemento tiene sesgo igual a cero, pero se pueden construir árboles muy distintos con esta propiedad lo que implica un alta variabilidad en la calse de funciones que representan. Una forma de establecer un compromiso entre sesgo y varianza es podar hacia arriba los nodos del árbol tratando de  minimizar un criterio-compromiso entre fidelidad de ajuste y número de nodos
# EJ 8
De acuerdo a las restricciones de KKT del modelo SVM-Hard-Dual diga si todo punto $({\bf x_n},y_n)$ verificando $y_n({\bf w}^{*T}{\bf x}_n+b^*)=1$  es un vector soporte de la solución. Argumente su decisión. ( * significa el valor estimado)  

Conteste con argumentos técnicos
### Solución
La solución del problem SVM-Hard establecen que los puntos con  $\alpha^*>0$ son los vectores soporte . Pero la condición de KKT solo establece que  se verifique $\alpha^*(y_n({\bf w}^T{\bf x}_n+b)-1)=0$ . Por tanto puede haber puntos no vectores soporte, es decir $\alpha^*=0$ verificando  $y_n({\bf w}^T{\bf x}_n+b)=1$. Es fácil encontrar ejemplos en R^2 con puntos redundantes sobre los márgenes del pasillo de la solución.
# EJ 9
Cuando se usa "early_stopping" en el ajuste de una red neuronal es muy posible que obtengamos el mínimo de la validación en una iteración anterior a haber entrenado la red con todos los datos del conjunto de entrenamiento. Analice esta situación y diga:

a) ¿Está en conflicto esta situación con la propiedad establecida por las curvas de aprendizaje, que nos dice que cuantos más datos usemos para entrenar un modelo mejor modelo  se obtiene?

b) ¿Que pasaría, en ese caso, si seguimos entrenando hasta terminar con todos los datos?

Justifique sus decisiones con argumentos técnicos apropiados.
### Solución
a) La curva de aprendizaje nos habla de la conducta promedio del ajuste de un modelo concreto cuando el número de datos crece. No es el caso en early-stooping ya que en este caso recorremos una clase de funciones  H añadiendo nuevos datos en el ajuste de forma que el modelo cambia en cada iteración. Por tanto no está en conflicto porque son cosas distintas.

b) Si una vez alcanzado el mínimo de la validación seguimos entrenando hasta  agotar todos los datos de entrenamiento, podemos estar sobre-ajustando nuestro modelo a los datos. Las RRNN como aproximadores universales definen clases de funciones de muy alta la capacidad que permite ajustar todo el ruido estocástico presente en la muestra. Por tanto es necesario parar en algún punto donde el error de validación crezca frente al error de ajuste. La elección de este momento es un cálculo heurístico.

# EJ 10
Trabaja para una empresa que explota un criadero artificial de diversas especies de peces en un lago. La empresa desea  construir un modelo para predecir los kilos de pescado comercializables en tres instantes de tiempo futuro, a una semana, a un mes y a tres meses. Para ello usará los datos de las capturas diarias  para su comercialización durante los últimos seis meses.  Analize la situación, haga las hipótesis que considere necesarias  y diga que posibilidades tiene la empresa de obtener los resultados que desea. 

  

Conteste con argumentos técnicos
### Solución
No es posible predecir con precisión a medio y largo plazo.la distribución de tamaño de los peces no se puede conocer ya que no se obtienen muestras representativas  con las redes usadas. Solo conocemos predictores que funcionan bajo la hipótesis de distribuciones de poblaciíon sin cambios en le tiempo.

La toma de muestra con las redes usadas  introduce necesariamente un sesgo en los datos en aquellos  tamaños que no son capturados por dichas redes.
# EJ 11
a) Considere la formulación del clasificador primal de SVM-Hard. Defina el contexto bajo el cual este enfoque es realizable e identifique su principal contribución metodológica.  

b) Considere el problema de clasificación  dual de SVM-Hard.  Describa su relación con el problema primal y diga como contribuye a la solución del problema de optimización.

c) Considere el caso de tareas de clasificación con muestras separables pero con fronteras de decisión muy complejas. ¿Que aporta el enfoque  SVM a la solución de este problema y como lo hace? De detalles. 

  

Conteste con argumentos técnicos
### Solución
a.- Obtener el hiperplano separador de máximo margen en el espacio muestral cuando el tamaño de la muestra es superior a la dimensión de las mismas. Añade a los anteriores la solución de máximo margen.  

b.- La solución del problema dual se basa en el teorema-dualidad que nos permite cambiar el orden en las optimizaciones entre los parámetros del modelo y los multiplicadores asociados a las restricciones. Como consecuencia, los parámetros del primal se fijan como funciones de los multiplicadores lo que permite resolver  un problema-QP para obtener los multiplicadores.  Este enfoque permite obtener soluciones separables de máximo margen en espacios de alta dimensionalidad. En particular cuando el tamaño la dimensión de las muestras es mayor que el tamaño muestral.

c.- La solución hard-dual  permite el uso de funciones Kernel para calcular los productos escalares, en el espacio Z-expandido,  presentes en la matriz Q del problema de optimización sin necesidad de tener que precomputarlas y almacenarlas.





